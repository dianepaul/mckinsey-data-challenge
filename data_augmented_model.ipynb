{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78d327b-b487-4963-af41-3074eb80c374",
   "metadata": {},
   "source": [
    "# 0. Discover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c5726-fbc6-4d41-9b5a-4647f635a79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f4deb-425f-43f3-b4e6-b1f80f5b06f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.plot import show, show_hist\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90749b82-c4cd-444d-9a71-31e9362d0e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_metadata = '../hfactory_magic_folders/cleanr/train data/metadata.csv'\n",
    "df_meta = pd.read_csv(path_metadata)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950839b-0293-4ff2-9b84-83519d1521d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hfactory_magic_folders/cleanr/train data/images/plume/20230101_methane_mixing_ratio_id_4928.tif\"\n",
    "example_image = rasterio.open(path)\n",
    "show(example_image, cmap=\"Greys\", title=\"Satelite image of the location with ID 4928 in 2023-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8e132-e8b6-4925-87f7-76f4ef763118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (df_meta['id_coord'] == 'id_4928') & (df_meta['date'] == 20230101)\n",
    "df_meta[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec28a22-f8fd-44c6-81d5-cc12077bd295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../hfactory_magic_folders/cleanr/train data/images/no_plume/20230330_methane_mixing_ratio_id_6609.tif\"\n",
    "example_image = rasterio.open(path)\n",
    "show(example_image, cmap=\"Greys\", title=\"Satelite image of the location with ID 6609 in 2023-03-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cccd04-faa4-402b-bc55-25af0c38fade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition = (df_meta['id_coord'] == 'id_6609') & (df_meta['date'] == 20230330)\n",
    "df_meta[condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858b737-7836-4560-96a5-ae4f86018d2a",
   "metadata": {},
   "source": [
    "# I. Data augmentation addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728904c0-8859-4665-b11a-6c78d75bdfae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory path containing your original images\n",
    "original_directory = \"../hfactory_magic_folders/cleanr/train data/images/plume\"\n",
    "\n",
    "# Output directory for augmented images\n",
    "output_directory = \"data_augmented/plume\"\n",
    "\n",
    "# Function to rotate images and save both original and rotated versions\n",
    "def augment_and_save_images(original_directory, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "    for filename in os.listdir(original_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".tif\"):\n",
    "            # Load the original image\n",
    "            original_image_path = os.path.join(original_directory, filename)\n",
    "            original_image = Image.open(original_image_path)\n",
    "\n",
    "            # Rotate the original image by 90 degrees\n",
    "            rotated_image = original_image.rotate(90)\n",
    "            \n",
    "            # Flip the image horizontally\n",
    "            flipped_image = original_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            # Save the original image and the rotated image in the output directory\n",
    "            original_image.save(os.path.join(output_directory, f\"original_{filename}\"))\n",
    "            rotated_image.save(os.path.join(output_directory, f\"rotated_{filename}\"))\n",
    "            flipped_image.save(os.path.join(output_directory, f\"flipped_{filename}\"))\n",
    "\n",
    "# Call the function to augment and save images\n",
    "# augment_and_save_images(original_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a0794-0372-47d7-982b-478f09b5f9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory path containing your original images\n",
    "original_directory = \"../hfactory_magic_folders/cleanr/train data/images/no_plume\"\n",
    "\n",
    "# Output directory for augmented images\n",
    "output_directory = \"data_augmented/no_plume\"\n",
    "\n",
    "# Function to rotate images and save both original and rotated versions\n",
    "def augment_and_save_images(original_directory, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "    for filename in os.listdir(original_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".tif\"):\n",
    "            # Load the original image\n",
    "            original_image_path = os.path.join(original_directory, filename)\n",
    "            original_image = Image.open(original_image_path)\n",
    "\n",
    "            # Rotate the original image by 90 degrees\n",
    "            rotated_image = original_image.rotate(90)\n",
    "            \n",
    "            # Flip the image horizontally\n",
    "            flipped_image = original_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            # Save the original image and the rotated image in the output directory\n",
    "            original_image.save(os.path.join(output_directory, f\"original_{filename}\"))\n",
    "            rotated_image.save(os.path.join(output_directory, f\"rotated_{filename}\"))\n",
    "            flipped_image.save(os.path.join(output_directory, f\"flipped_{filename}\"))\n",
    "\n",
    "# Call the function to augment and save images\n",
    "# augment_and_save_images(original_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16cf9f-0e4e-4834-95e8-1eb8c6baff18",
   "metadata": {},
   "source": [
    "# II. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f81c03-bf3c-499e-9bc2-5ea2a32aa942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05999bfd-c28f-4cb8-9bde-b8df3e58f7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_tif(image_str):\n",
    "    if image_str[-4:] == \".tif\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaf54c-fd0e-42b8-9c91-77096002bc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images (you can adjust the normalization values)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = 'data_augmented/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Create subsets for training and test data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for both subsets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9bee8c-6b78-45f9-b8f0-8bda09320ac4",
   "metadata": {},
   "source": [
    "# III. Pipeline preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c90fe-5626-4c08-afcf-b95952ba29a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    #Obtain a list of prediction scores. If the prediction score >= 0.5, it means the image contains a plume, else not\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            if outputs.cpu().size() == torch.Size([]):\n",
    "                predictions += [outputs.cpu().item()]\n",
    "                targets += [labels.cpu().item()]\n",
    "            else:\n",
    "                predictions += outputs.cpu().tolist()\n",
    "                targets += labels.cpu().tolist()\n",
    "    accuracy = accuracy_score(targets, [round(p) for p in predictions])\n",
    "    auc_score = roc_auc_score(targets, predictions) * 100\n",
    "    return accuracy, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83d9cb-2497-4782-9421-ca3264c75ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, optimizer, loss, num_epochs=10):\n",
    "    # Lists to store the loss and AUC scores\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    auc_scores = []\n",
    "    test_acc = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "    \n",
    "            # Ensure labels are of type torch.FloatTensor\n",
    "            labels = labels.float().to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "    \n",
    "            # Reshape the labels to match the shape of outputs\n",
    "            labels = labels.view_as(outputs)\n",
    "    \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "        train_loss /= len(train_dataset)\n",
    "    \n",
    "        # Calculate test loss and metrics\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        # Iterate through the test loader\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.no_grad():  # Ensure no gradient calculation during inference\n",
    "                outputs = model(images).squeeze()\n",
    "            labels = labels.view_as(outputs)\n",
    "\n",
    "            # Calculate the loss (assuming you're using BCEWithLogitsLoss)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate the test loss\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Calculate the average test loss\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "    \n",
    "        test_accuracy, test_auc_score = evaluate(model, test_loader)  # Ensure evaluate function returns these metrics\n",
    "    \n",
    "        # Store the loss and AUC score for plotting\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)  # Update test loss here\n",
    "        auc_scores.append(test_auc_score)\n",
    "        test_acc.append(test_accuracy)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}, Test AUC: {test_auc_score:.2f}%\")\n",
    "        \n",
    "    return train_losses, test_losses, auc_scores, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc9317-43dd-4e48-b9e4-61e859c18adf",
   "metadata": {},
   "source": [
    "# IV. Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf84d3-6795-40f4-ba5a-8bd408c2836f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class PlumeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlumeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(nn.functional.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(nn.functional.relu(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = self.dropout(nn.functional.relu(self.fc1(x)))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989dadd-4ec5-43d5-b7c5-a6d340d061a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PlumeCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e277409-e387-4363-8f31-c4ce42890e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses, auc_scores, test_acc = train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e614ec-3ca3-4464-b364-b81ccb2c0417",
   "metadata": {},
   "source": [
    "# V. Plot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee844241-83d6-4ab1-99d4-9353d89e1fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting caracteristics.\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'darkblue',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }\n",
    "figure_size = (15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6191304-25f8-49fa-b2bb-ce0fff813c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, test_losses):\n",
    "    list_epochs = [k for k in range(len(train_losses))]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(list_epochs, train_losses, c='blue', label='Training loss')\n",
    "    ax.plot(list_epochs, test_losses, c='red', label='Test loss')\n",
    "    \n",
    "    ax.set_title('Training and test losses', fontdict=font)\n",
    "    ax.set_xlabel('Epoch', fontdict=font)\n",
    "    ax.set_ylabel('Loss (BCE)', fontdict=font)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7784a8-3751-4de2-a40b-b35f9008023a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric, metric_name):\n",
    "    list_epochs = [k for k in range(len(metric))]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(list_epochs, metric, label=metric_name)\n",
    "    \n",
    "    ax.set_title('Metric: ' + metric_name, fontdict=font)\n",
    "    ax.set_xlabel('Epoch', fontdict=font)\n",
    "    ax.set_ylabel(metric_name, fontdict=font)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bba0e-e71f-486d-be79-ffbcf04a4cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15535b-838c-49e0-a06c-5f85362180f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_metric(auc_scores, 'AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b43280-94fc-4b89-96ca-a20ca26440c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_metric(test_acc, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf0f44-48ba-4062-860e-cc316046d3e5",
   "metadata": {},
   "source": [
    "# VI. Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7e596-8248-443c-9023-beb52e866abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric_models(metric, metric_name, list_model_names):\n",
    "    \"\"\"\n",
    "    metric: for the same metric, list of list of metrics.\n",
    "    \"\"\"\n",
    "    n_models = len(list_model_names)\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    for k in range(n_models):\n",
    "        list_epochs = [k for k in range(len(metric[k]))]\n",
    "        ax.plot(list_epochs, metric[k], label=list_model_names[k])\n",
    "    ax.set_title(metric_name + ' for different models', fontdict=font)\n",
    "    ax.set_xlabel('Epoch', fontdict=font)\n",
    "    ax.set_ylabel(metric_name, fontdict=font)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed6ca9-aa0f-4c64-8bdb-e8c418bd3a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images (you can adjust the normalization values)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = 'window_3/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Create subsets for training and test data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for both subsets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PlumeCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses_window_3, test_losses_window_3, auc_scores_window_3, test_acc_window_3 = train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdbb8c-e9d6-4d26-a305-14f0f0c29983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images (you can adjust the normalization values)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = 'window_4/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Create subsets for training and test data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for both subsets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PlumeCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses_window_4, test_losses_window_4, auc_scores_window_4, test_acc_window_4 = train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a82b89-fdd1-4121-821a-12e6b77af510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images (you can adjust the normalization values)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = '../hfactory_magic_folders/cleanr/train data/images/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Create subsets for training and test data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for both subsets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PlumeCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses_base, test_losses_base, auc_scores_base, test_acc_base = train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33b6fb-ef69-4696-a96f-6030f8d1ae76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = [auc_scores_base, auc_scores, auc_scores_window_3, auc_scores_window_4]\n",
    "metric_name = 'AUC score'\n",
    "list_model_names = ['Base CNN', 'CNN on data augmented', 'CNN on window_3', 'CNN on window_4']\n",
    "plot_metric_models(metric, metric_name, list_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc42b17-d2d0-45b4-b52e-df79ff1f7d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = [test_acc_base, test_acc, test_acc_window_3, test_acc_window_4]\n",
    "metric_name = 'Test accuracy'\n",
    "list_model_names = ['Base CNN', 'CNN on data augmented', 'CNN on window_3', 'CNN on window_4']\n",
    "plot_metric_models(metric, metric_name, list_model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa5a54-b2e1-4e9b-9cfa-0eae04c05770",
   "metadata": {},
   "source": [
    "# VII. ResNet fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb949b-0658-4d98-8e74-58f2ab9db530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd0bf0-df53-4ac1-8e9f-04f6be7b4817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images (you can adjust the normalization values)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = '../hfactory_magic_folders/cleanr/train data/images/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "# Perform a stratified split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Create subsets for training and test data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create data loaders for both subsets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load a pretrained ResNet model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final classification layer for binary classification (1 output neuron) with sigmoid activation\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),\n",
    "    nn.Sigmoid()  # Add sigmoid activation\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Place the model on GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Done\")\n",
    "\n",
    "train_losses_resnet, test_losses_resnet, auc_scores_resnet, test_acc_resnet = train_model(model, train_loader, test_loader, optimizer, criterion, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14b912-33e5-445c-b1a2-940e94ce1a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = [test_acc_base, test_acc_resnet]\n",
    "metric_name = 'Test accuracy'\n",
    "list_model_names = ['Base CNN', 'ResNet finetuned']\n",
    "plot_metric_models(metric, metric_name, list_model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cadaf-daf4-4568-95fa-116d902d9d1c",
   "metadata": {},
   "source": [
    "# For later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a22b9-3e79-4ade-9ebf-a945d25a77da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel (RGB)\n",
    "    transforms.Resize((224, 224)),  # Resize to match the input size of ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = '../hfactory_magic_folders/cleanr/train data/images/'\n",
    "\n",
    "# Create the ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform, is_valid_file=is_tif)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets (adjust ratios as needed)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Define the data loaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
