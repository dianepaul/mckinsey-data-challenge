{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d83f88",
   "metadata": {},
   "source": [
    "# Methane detection hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e50192",
   "metadata": {},
   "source": [
    "### Goal : detect methane leaks in the atmosphere based on satelite images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabaf15",
   "metadata": {},
   "source": [
    "It's a binary classification problem : does the image contain a plume of methane or not ?\n",
    "\n",
    "In order to do that, a dataset containing images in `tif` format is provided along with metadata including :\n",
    "* path\n",
    "* date the satelite image was taken\n",
    "* class (`plume` or `no_plume`)\n",
    "* an ID identifying the location\n",
    "* latitude and longitude coordinates locating the center of the plume (`lat`,`lon`)\n",
    "* pixel coordinates locating the center of the plume in the image (`coord_x`,`coord_y`). Please be midnful that the axis origin (0,0) is at the top left corner of the image\n",
    "\n",
    "The dataset contains two folders:\n",
    "- `plume` : contains all images with plumes of methane.\n",
    "- `no_plume` : contains all images with no plume of methane.\n",
    "\n",
    "\n",
    "**All images have a resolution of 64x64 and they are in gray scale (2D-arrays).**\n",
    "\n",
    "Images names are written in the following format `{date}_methane_mixing_ratio_id_{location id}.tif`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879916d",
   "metadata": {},
   "source": [
    "### 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70300d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047fae5",
   "metadata": {},
   "source": [
    "### 2. Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2733efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1c296",
   "metadata": {},
   "source": [
    "### 3. Read an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779fb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image  # Import the Image class from PIL\n",
    "\n",
    "\n",
    "class PlumeDataset:\n",
    "    def __init__(self, plume_dir, no_plume_dir, image_size=(64, 64)):\n",
    "        self.plume_images = [os.path.join(plume_dir, img) for img in os.listdir(plume_dir)]\n",
    "        self.no_plume_images = [os.path.join(no_plume_dir, img) for img in os.listdir(no_plume_dir)]\n",
    "        self.images = self.plume_images + self.no_plume_images\n",
    "        self.labels = [1] * len(self.plume_images) + [0] * len(self.no_plume_images)\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        # Check if the file is .DS_Store and skip it\n",
    "        if image_path.endswith('.DS_Store'):\n",
    "            return None\n",
    "\n",
    "        if os.path.isfile(image_path):  # Check if the file exists\n",
    "            img = Image.open(image_path)\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "            img = img.resize(self.image_size)  # Resize to your desired dimensions\n",
    "            img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            return img\n",
    "        else:\n",
    "            # Handle the case where the file does not exist (e.g., .DS_Store)\n",
    "            # You can choose to return None or raise an exception here.\n",
    "            return None\n",
    "\n",
    "    def get_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for image_path, label in zip(self.images, self.labels):\n",
    "            img = self.load_and_preprocess_image(image_path)\n",
    "            if img is not None:\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = to_categorical(y, num_classes=2)  # Convert labels to one-hot encoding\n",
    "\n",
    "        return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "plume_dir = 'cleanr/train data/images/plume'\n",
    "no_plume_dir = 'cleanr/train data/images/no_plume'\n",
    "\n",
    "# Create an instance of the PlumeDataset\n",
    "plume_dataset = PlumeDataset(plume_dir, no_plume_dir, image_size=(64, 64))\n",
    "\n",
    "# Load and preprocess the data\n",
    "X, y = plume_dataset.get_data()\n",
    "\n",
    "# Now, X contains the preprocessed images, and y contains the corresponding labels in one-hot encoding.\n",
    "\n",
    "# Split the data into training and validation sets as needed\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69562d1",
   "metadata": {},
   "source": [
    "### 5. Metadata\n",
    "\n",
    "- one pixel = 2.4 km x 2.4 km\n",
    "- Lat Long = latitude and longitude of the estimated methane plume center\n",
    "- coord_x coord_y = plume position in the image (origin = top / left) in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9be06f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"cleanr/train data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdaf547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ed5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define your CNN model\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(64, 64, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))  # Dropout layer as specified\n",
    "model.add(Dense(2, activation='softmax'))  # Two classes: 'plume' and 'no_plume'\n",
    "\n",
    "\n",
    "def roc_auc(y_true, y_pred):\n",
    "    # Calculate ROC AUC score using scikit-learn's roc_auc_score function\n",
    "    auc = tf.py_function(roc_auc_score, (y_true, y_pred), tf.float32)\n",
    "    return auc\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', roc_auc])\n",
    "\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=()):\n",
    "        super(Callback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred)\n",
    "        print(\"\\nROC AUC: {:.4f}\\n\".format(roc_auc))\n",
    "\n",
    "roc_auc_callback = RocAucEvaluation(validation_data=(X_val, y_val))\n",
    "\n",
    "# Train the model with class weights\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[roc_auc_callback]\n",
    ")\n",
    "\n",
    "# Save the model if needed\n",
    "model.save('methane_detection_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf0dbfeb",
   "metadata": {},
   "source": [
    "Model with Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "plume_dir = 'data_augmented/plume'\n",
    "no_plume_dir = 'data_augmented/no_plume'\n",
    "\n",
    "# Create an instance of the PlumeDataset\n",
    "plume_dataset = PlumeDataset(plume_dir, no_plume_dir, image_size=(64, 64))\n",
    "\n",
    "# Load and preprocess the data\n",
    "X, y = plume_dataset.get_data()\n",
    "\n",
    "# Now, X contains the preprocessed images, and y contains the corresponding labels in one-hot encoding.\n",
    "\n",
    "# Split the data into training and validation sets as needed\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c1cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define your CNN model\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(64, 64, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))  # Dropout layer as specified\n",
    "model.add(Dense(2, activation='softmax'))  # Two classes: 'plume' and 'no_plume'\n",
    "\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=()):\n",
    "        super(Callback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred)\n",
    "        print(\"\\nROC AUC: {:.4f}\\n\".format(roc_auc))\n",
    "\n",
    "roc_auc_callback = RocAucEvaluation(validation_data=(X_val, y_val))\n",
    "\n",
    "# Train the model with class weights\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[roc_auc_callback]\n",
    ")\n",
    "\n",
    "# Save the model if needed\n",
    "model.save('methane_detection_model_augmented.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7b944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
