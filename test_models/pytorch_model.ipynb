{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253223c-b8f8-43f6-b44b-2e160cb14b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show, show_hist\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26173d-9b27-4087-95f6-97d108d0c970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_train_plume = \"cleanr/train data/images/plume\"\n",
    "path_train_no_plume = \"cleanr/train data/images/no_plume\"\n",
    "path_test = \"cleanr/test data/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e493f-66a7-4575-b369-5b983dc943f0",
   "metadata": {},
   "source": [
    "## DATA EXPLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a482aae-f082-4f2b-9fd4-d459fe480db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"nombre d'image plume :{len(os.listdir(path_train_plume))}\")\n",
    "print(f\"nombre d'image no plume :{len(os.listdir(path_train_no_plume))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1acab08-0bbe-497b-8575-5c7237488538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_img = path_train_no_plume + \"/\" + os.listdir(path_train_no_plume)[12]\n",
    "example_image = rasterio.open(path_img)\n",
    "show(example_image, cmap=\"Greys\", title=\"ex image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fab695-7b25-42ac-b7d9-48638e244b97",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b8b38-84ea-403b-bc2b-3f0df1b89ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a transform for data augmentation and normalization\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define dataset class\n",
    "class PlumeDataset(Dataset):\n",
    "    def __init__(self, plume_dir, no_plume_dir, transform=None):\n",
    "        self.plume_images = [\n",
    "            os.path.join(plume_dir, img) for img in os.listdir(plume_dir)\n",
    "        ]\n",
    "        self.no_plume_images = [\n",
    "            os.path.join(no_plume_dir, img) for img in os.listdir(no_plume_dir)\n",
    "        ]\n",
    "        self.images = self.plume_images + self.no_plume_images\n",
    "        self.targets = [1] * len(self.plume_images) + [0] * len(self.no_plume_images)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert(\"L\")\n",
    "        target = self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "# Create datasets for both \"plume\" and \"no plume\" classes\n",
    "dataset = PlumeDataset(path_train_plume, path_train_no_plume, transform=transform)\n",
    "\n",
    "# Split the combined dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Print the number of samples in each class\n",
    "print(f\"Number of rows in dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2d618-8f55-4f8b-8799-ed8bc143b086",
   "metadata": {},
   "source": [
    "## MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe3e7b-2a16-4e05-a398-980b8a38ecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define CNN model\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(nn.functional.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(nn.functional.relu(self.conv2(x))))\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = self.dropout(nn.functional.relu(self.fc1(x)))\n",
    "        x = nn.functional.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca42fa-5827-4aca-9045-cd274da34ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install resnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0811a-58a9-4ba8-9c1a-4aa666553609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from resnet_pytorch import ResNet \n",
    "model_ResNet = ResNet.from_pretrained('resnet18', num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610237de-4bb5-43df-986e-5d6d55c74146",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d2137-eaae-40bd-8ba0-0bb8aebefc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Create an instance of the model\n",
    "num_classes = 2  # Assuming 2 classes: plume methane cloud and not plume methane cloud\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = model_ResNet\n",
    "# Define a loss function and an optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d7210-c2bc-4763-8eaf-310965202116",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0744581-99fa-42df-9fd8-ba67d2888536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have already trained the model and defined the evaluation dataset and data loader (val_loader)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Calculate the binary classification accuracy\n",
    "        predicted = (outputs > 0.5).float()  # Assuming you're using a sigmoid activation\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = (total_correct / total_samples) * 100.0\n",
    "average_loss = total_loss / len(val_loader)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Average Validation Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ea7cc-7e08-465e-861a-ef981071c68f",
   "metadata": {},
   "source": [
    "## CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a2499-e342-499a-a957-5342dbbff143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a trained model and a DataLoader for validation data (val_loader)\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = (outputs > 0.5).float()  # Assuming you're using a sigmoid activation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(\n",
    "        confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "confusion = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Assuming class_names is a list of class names (e.g., [\"No Plume\", \"Plume\"])\n",
    "class_names = [\"No Plume\", \"Plume\"]\n",
    "plot_confusion_matrix(confusion, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dcfb6-2438-425b-80c3-01ab82a8753c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
